{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab-5_MNIST Digit Recognizer (Neural Network and it_s Variations).ipynb","provenance":[{"file_id":"1JXiP9YzF-roL3Vt2UOLYKsRYf2yauTRK","timestamp":1592642571900}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1f7d66079f6647aca07eff6c57df21b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3f253634b825465c9175ddfd46a22bb1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5038409f80764e1787f8e86a9ebd12dd","IPY_MODEL_0cd70fbdc8a64b9a80635c8e305a865d","IPY_MODEL_6087508329bd4267af4efd359cb0be0b"]}},"3f253634b825465c9175ddfd46a22bb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5038409f80764e1787f8e86a9ebd12dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_481a89a2f5ca44279a29df4eb1ae07e1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_56ae1c0639904baf997e4cb66b71c6cc"}},"0cd70fbdc8a64b9a80635c8e305a865d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e2f56440f1a44e0fbf6d1df1173cac82","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9912422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9912422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c8b4fc63b68464c8f18a9766cc7a7c4"}},"6087508329bd4267af4efd359cb0be0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7e0b0a8b11ff4d289e394479cb8e7221","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9913344/? [00:04&lt;00:00, 2463323.04it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e8c7bf0a93a84111b17409322d5ce960"}},"481a89a2f5ca44279a29df4eb1ae07e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"56ae1c0639904baf997e4cb66b71c6cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e2f56440f1a44e0fbf6d1df1173cac82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2c8b4fc63b68464c8f18a9766cc7a7c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e0b0a8b11ff4d289e394479cb8e7221":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e8c7bf0a93a84111b17409322d5ce960":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"402ca05090ff46579eb684777093eaa0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8e51b742dc274423b1cdd29bafdad7e9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d3cf053a53e64f749d6c05bf29f954c0","IPY_MODEL_a659afa5d2424906912fa992691a0444","IPY_MODEL_92bbd964972d429c9ac94be10a8cf1e0"]}},"8e51b742dc274423b1cdd29bafdad7e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d3cf053a53e64f749d6c05bf29f954c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c80076510128489a9e9489eb656cdf67","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_16d0146687884ebeb78ec71005366a2b"}},"a659afa5d2424906912fa992691a0444":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_88ce78ef94ba4c209ebc2f8e554729be","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_306275d483a44b619200a33ee59df371"}},"92bbd964972d429c9ac94be10a8cf1e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_85a5416f9f154a71b3ce0fbeb7dd92b7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [00:00&lt;00:00, 613887.31it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_169fa2c7bce2465281618cd33c42183b"}},"c80076510128489a9e9489eb656cdf67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"16d0146687884ebeb78ec71005366a2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88ce78ef94ba4c209ebc2f8e554729be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"306275d483a44b619200a33ee59df371":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"85a5416f9f154a71b3ce0fbeb7dd92b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"169fa2c7bce2465281618cd33c42183b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2179a0637bd2491c95f20640ffd95fbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_59f04eea8b7140f08a858b3a85d2096f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_50efe800836f42018f98cc4e6e362df8","IPY_MODEL_79256a0c82794ae086c1fa34a52ad78c","IPY_MODEL_fcbc3acf1f2d4b51838c303820e3eb59"]}},"59f04eea8b7140f08a858b3a85d2096f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"50efe800836f42018f98cc4e6e362df8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d89d015cc71549bf976ba048032d227f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dec73decb6d749c0a697fefb6e7a4ff9"}},"79256a0c82794ae086c1fa34a52ad78c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_20efea7a6ab149f385bb0517b292fb47","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1648877,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1648877,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5aab406ef7ce48f4852449e2b65591fa"}},"fcbc3acf1f2d4b51838c303820e3eb59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fafb69743ac144e0874c472c379ee9c6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1649664/? [00:00&lt;00:00, 1475937.14it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_45841f83c928492192fff1a1a483850b"}},"d89d015cc71549bf976ba048032d227f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dec73decb6d749c0a697fefb6e7a4ff9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"20efea7a6ab149f385bb0517b292fb47":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5aab406ef7ce48f4852449e2b65591fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fafb69743ac144e0874c472c379ee9c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"45841f83c928492192fff1a1a483850b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab6a1d6847d0444ba59f7b972f80983c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6f3bf0285bfd461c9646bfb8a606e8c2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6b1067ef124044519abd9358d74ee9b9","IPY_MODEL_8f6decc51eee4be1be9028092a5838ab","IPY_MODEL_051ad325ee3a4d349b74c7c73c39a674"]}},"6f3bf0285bfd461c9646bfb8a606e8c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b1067ef124044519abd9358d74ee9b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_87ecae9795c14ad98aa46cc5ac588d53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_64881253918c4f37b5b3fb2fccaf0782"}},"8f6decc51eee4be1be9028092a5838ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_171aac87f9244733869f0723673332f8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4542,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4542,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46870b3cb2854ffabfb81f6ec0a2b53f"}},"051ad325ee3a4d349b74c7c73c39a674":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_35695894ac734abfa84a0dcb10a1e15c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5120/? [00:00&lt;00:00, 165860.87it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b96ace6de554247a86d2792a239c723"}},"87ecae9795c14ad98aa46cc5ac588d53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"64881253918c4f37b5b3fb2fccaf0782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"171aac87f9244733869f0723673332f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"46870b3cb2854ffabfb81f6ec0a2b53f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"35695894ac734abfa84a0dcb10a1e15c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2b96ace6de554247a86d2792a239c723":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"IU2vVOns0lmz"},"source":["\n","\n","> Notebook Prepared by: Mir Tafseer Nayeem\n","\n","\n","> Course Teacher: Sanzana Karim Lora\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"z0tKD3f1Nt8y"},"source":["## MNIST Digit Recognizer (Neural Network)"]},{"cell_type":"markdown","metadata":{"id":"SyzBofWXmt0H"},"source":["\n","\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1VT-muG5HJoWaT9jwlmI6fe_7CjbW9x8I\" width=\"300\">\n","</div>\n","\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1foK0jI3dSuvCBBUbiqVKMiLn7x3ngA_x\" width=\"350\" height=\"200\">\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"7ILa4hbOxdnJ"},"source":["## One Layer FNN with Sigmoid Activation"]},{"cell_type":"code","metadata":{"id":"HJ1dVc9mgbN8","executionInfo":{"status":"ok","timestamp":1630850402996,"user_tz":-360,"elapsed":4419,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o9vfh-4mtXt3"},"source":["<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=16ZWsh6DrrwuzC4stYhsmcpIEGCke33Jc\" width=\"480\">\n","</div>\n"]},{"cell_type":"markdown","metadata":{"id":"EL0F4kOtWER5"},"source":[" - Our input size is determined by the size of the image **(height x width) = (28X28)**. Hence the size of our input is **784 (28 x 28)**.\n","\n"," - When we pass an image to our model, it will try to predict if it's **0, 1, 2, 3, 4, 5, 6, 7, 8, or 9**. That is a total of 10 classes, hence we have an output size of 10.\n","\n"," - Determining the **hidden layer size** is one of the crutial part. The first layer prior to the non-linear layer. This can be any **real number**. A large number of hidden nodes denotes a **bigger model with more parameters**. \n","\n","- The bigger model isn't **always the better model**. On the other hand, bigger model requires **more training samples** to learn and converge to a good model. \n","\n","- Actually a bigger model **requires more training samples** to learn and converge to a good model. Hence, it is wise to pick the model size for the problem at hand. Because it is a simple problem of recognizing digits, we typically would not need a big model to achieve good results.\n","\n","- Moreover, too small of a hidden size would mean there would be **insufficient model capacity to predict competently**. Too small of a capacity denotes a **smaller brain capacity** so no matter how many training samples you provide, it has a maximum capacity boundary in terms of its **predictive power**."]},{"cell_type":"markdown","metadata":{"id":"fXVIydDCxDPS"},"source":["- **Input dimension:**\n","  - Size of image: $28 \\times 28 = 784$\n","\n","- **Output dimension: 10**\n","  - 0, 1, 2, 3, 4, 5, 6, 7, 8, 9"]},{"cell_type":"code","metadata":{"id":"o5hVijghPqz0","executionInfo":{"status":"ok","timestamp":1630850421838,"user_tz":-360,"elapsed":348,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}}},"source":["# Hyperparameters\n","\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100 # num of hidden nodes\n","output_dim = 10\n","\n","learning_rate = 0.1  # More power so we can learn faster! previously it was 0.001\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C4R6x4MvEsOT"},"source":["### Loading MNIST Dataset"]},{"cell_type":"code","metadata":{"id":"eUumuKA-cahD","colab":{"base_uri":"https://localhost:8080/","height":467,"referenced_widgets":["1f7d66079f6647aca07eff6c57df21b7","3f253634b825465c9175ddfd46a22bb1","5038409f80764e1787f8e86a9ebd12dd","0cd70fbdc8a64b9a80635c8e305a865d","6087508329bd4267af4efd359cb0be0b","481a89a2f5ca44279a29df4eb1ae07e1","56ae1c0639904baf997e4cb66b71c6cc","e2f56440f1a44e0fbf6d1df1173cac82","2c8b4fc63b68464c8f18a9766cc7a7c4","7e0b0a8b11ff4d289e394479cb8e7221","e8c7bf0a93a84111b17409322d5ce960","402ca05090ff46579eb684777093eaa0","8e51b742dc274423b1cdd29bafdad7e9","d3cf053a53e64f749d6c05bf29f954c0","a659afa5d2424906912fa992691a0444","92bbd964972d429c9ac94be10a8cf1e0","c80076510128489a9e9489eb656cdf67","16d0146687884ebeb78ec71005366a2b","88ce78ef94ba4c209ebc2f8e554729be","306275d483a44b619200a33ee59df371","85a5416f9f154a71b3ce0fbeb7dd92b7","169fa2c7bce2465281618cd33c42183b","2179a0637bd2491c95f20640ffd95fbe","59f04eea8b7140f08a858b3a85d2096f","50efe800836f42018f98cc4e6e362df8","79256a0c82794ae086c1fa34a52ad78c","fcbc3acf1f2d4b51838c303820e3eb59","d89d015cc71549bf976ba048032d227f","dec73decb6d749c0a697fefb6e7a4ff9","20efea7a6ab149f385bb0517b292fb47","5aab406ef7ce48f4852449e2b65591fa","fafb69743ac144e0874c472c379ee9c6","45841f83c928492192fff1a1a483850b","ab6a1d6847d0444ba59f7b972f80983c","6f3bf0285bfd461c9646bfb8a606e8c2","6b1067ef124044519abd9358d74ee9b9","8f6decc51eee4be1be9028092a5838ab","051ad325ee3a4d349b74c7c73c39a674","87ecae9795c14ad98aa46cc5ac588d53","64881253918c4f37b5b3fb2fccaf0782","171aac87f9244733869f0723673332f8","46870b3cb2854ffabfb81f6ec0a2b53f","35695894ac734abfa84a0dcb10a1e15c","2b96ace6de554247a86d2792a239c723"]},"executionInfo":{"status":"ok","timestamp":1630850462256,"user_tz":-360,"elapsed":5587,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}},"outputId":"86ff2084-ad13-4961-f9c5-702fd1385486"},"source":["'''\n","LOADING DATASET\n","'''\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","'''\n","MAKING DATASET ITERABLE\n","'''\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)  "],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f7d66079f6647aca07eff6c57df21b7","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"402ca05090ff46579eb684777093eaa0","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2179a0637bd2491c95f20640ffd95fbe","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab6a1d6847d0444ba59f7b972f80983c","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"]}]},{"cell_type":"code","metadata":{"id":"vmkMVvf8CLHf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630850477099,"user_tz":-360,"elapsed":366,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}},"outputId":"020abeb6-877e-4231-ae06-7b9e3d657c5e"},"source":["print(len(train_dataset))\n","print(len(test_dataset))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["60000\n","10000\n"]}]},{"cell_type":"code","metadata":{"id":"Isz6lbl4Iovx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628672200403,"user_tz":-360,"elapsed":5,"user":{"displayName":"Sanzana Karim Lora","photoUrl":"","userId":"02981705641542133061"}},"outputId":"e36dc0ca-0742-409e-c51c-d5434c578bf2"},"source":["# One Image Size\n","print(train_dataset[0][0].size())\n","print(train_dataset[0][0].numpy().shape)\n"," \n","# First Image Label\n","print(train_dataset[0][1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([1, 28, 28])\n","(1, 28, 28)\n","5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GQB8tvNUQZop"},"source":["<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1mn8G92moF0MqXhD0J-M7cPidCYXR0hHS\" width=\"680\" height=\"380\">\n","</div>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nRm3MYkW8QVU"},"source":["### Step #1 : Design your model using class"]},{"cell_type":"code","metadata":{"id":"6mydzEXpeu7G","executionInfo":{"status":"ok","timestamp":1630851073402,"user_tz":-360,"elapsed":344,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}}},"source":["class NeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","\n","        ### Non-linearity\n","        self.sigmoid = nn.Sigmoid()\n","\n","        ### Output layer\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        # Linear layer\n","        out  = self.linear_1(x)\n","        # Non-linearity\n","        out = self.sigmoid(out)\n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"HIfiAaZB1rJz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630851277818,"user_tz":-360,"elapsed":12101,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}},"outputId":"60f735bb-6101-48a1-becd-8c0bf7928e16"},"source":["'''\n","INSTANTIATE MODEL CLASS\n","'''\n","model = NeuralNetworkModel(input_size = input_dim,\n","                           num_classes = output_dim,\n","                           num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NeuralNetworkModel(\n","  (linear_1): Linear(in_features=784, out_features=100, bias=True)\n","  (sigmoid): Sigmoid()\n","  (linear_out): Linear(in_features=100, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"pdrDJPOKzdSp"},"source":["###Step #2 : Construct loss and optimizer\n","\n","Unlike linear regression, we do not use MSE here, we need Cross Entropy Loss to calculate our loss before we backpropagate and update our parameters.\n","\n","`criterion = nn.CrossEntropyLoss() ` \n","\n","It does 2 things at the same time.\n","\n","1. Computes softmax ([Logistic or Sigmoid]/softmax function)\n","2. Computes Cross Entropy Loss"]},{"cell_type":"code","metadata":{"id":"GM2q_XGHzcta","executionInfo":{"status":"ok","timestamp":1630851290691,"user_tz":-360,"elapsed":356,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}}},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I2Hb_JQ6AUok"},"source":["###Step #3 : Training: forward, loss, backward, step"]},{"cell_type":"code","metadata":{"id":"Q3Jb4vhRZI9p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630851340211,"user_tz":-360,"elapsed":26876,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}},"outputId":"8eeaa44b-0eec-4902-8303-fb503945fb23"},"source":["'''\n","TRAIN THE MODEL\n","'''\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration: 500. Loss: 0.6877970695495605. Accuracy: 86.05\n","Iteration: 1000. Loss: 0.4014284908771515. Accuracy: 89.62\n","Iteration: 1500. Loss: 0.3388463854789734. Accuracy: 90.46\n","Iteration: 2000. Loss: 0.2703365087509155. Accuracy: 91.14\n","Iteration: 2500. Loss: 0.4592069387435913. Accuracy: 91.64\n","Iteration: 3000. Loss: 0.225782111287117. Accuracy: 91.85\n"]}]},{"cell_type":"markdown","metadata":{"id":"t_5UaSvBJckA"},"source":["## Expanding Neural Network variants\n","\n","2 ways to expand a neural network\n","- Different non-linear activation\n","- More hidden layers"]},{"cell_type":"markdown","metadata":{"id":"sG1A_uEHL5uU"},"source":["## One Layer FNN with Tanh Activation"]},{"cell_type":"code","metadata":{"id":"cyXyrgHMw41l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630851437295,"user_tz":-360,"elapsed":27191,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}},"outputId":"bc10f67e-bb26-4302-fe34-a00cd5fd8dbc"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class NeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","\n","        ### Non-linearity\n","        self.tanh = nn.Tanh()\n","\n","        ### Output layer\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        # Linear layer\n","        out  = self.linear_1(x)\n","        # Non-linearity\n","        out = self.tanh(out)\n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","model = NeuralNetworkModel(input_size = input_dim,\n","                           num_classes = output_dim,\n","                           num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration: 500. Loss: 0.2644069194793701. Accuracy: 91.08\n","Iteration: 1000. Loss: 0.3766373097896576. Accuracy: 92.29\n","Iteration: 1500. Loss: 0.2569728493690491. Accuracy: 93.13\n","Iteration: 2000. Loss: 0.27380913496017456. Accuracy: 94.07\n","Iteration: 2500. Loss: 0.2212696522474289. Accuracy: 94.49\n","Iteration: 3000. Loss: 0.21792323887348175. Accuracy: 94.9\n"]}]},{"cell_type":"markdown","metadata":{"id":"hoxfWq6ZNPiL"},"source":["## One Layer FNN with ReLU Activation"]},{"cell_type":"code","metadata":{"id":"PGVrecUPMsyT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630851623762,"user_tz":-360,"elapsed":27280,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}},"outputId":"4ad3135a-78d0-4bc0-8c15-318727b7c368"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class NeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","\n","        ### Non-linearity\n","        self.relu = nn.ReLU()\n","\n","        ### Output layer\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        # Linear layer\n","        out  = self.linear_1(x)\n","        # Non-linearity\n","        out = self.relu(out)\n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","model = NeuralNetworkModel(input_size = input_dim,\n","                           num_classes = output_dim,\n","                           num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration: 500. Loss: 0.284953773021698. Accuracy: 91.17\n","Iteration: 1000. Loss: 0.20034259557724. Accuracy: 92.64\n","Iteration: 1500. Loss: 0.21764422953128815. Accuracy: 93.96\n","Iteration: 2000. Loss: 0.18177205324172974. Accuracy: 94.55\n","Iteration: 2500. Loss: 0.19560648500919342. Accuracy: 95.15\n","Iteration: 3000. Loss: 0.10493969172239304. Accuracy: 95.52\n"]}]},{"cell_type":"markdown","metadata":{"id":"T_r9Lq-O0FJi"},"source":["## Two Layer FNN with ReLU Activation"]},{"cell_type":"code","metadata":{"id":"YNhAoGbnNasI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630851762214,"user_tz":-360,"elapsed":27622,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}},"outputId":"a7883145-41f3-438f-f668-1958afe4e4d4"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class DeepNeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer: 784 --> 100\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","        ### Non-linearity in 1st hidden layer\n","        self.relu_1 = nn.ReLU()\n","\n","        ### 2nd hidden layer: 100 --> 100\n","        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n","        ### Non-linearity in 2nd hidden layer\n","        self.relu_2 = nn.ReLU()\n","\n","        ### Output layer: 100 --> 10\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        ### 1st hidden layer\n","        out  = self.linear_1(x)\n","        ### Non-linearity in 1st hidden layer\n","        out = self.relu_1(out)\n","        \n","        ### 2nd hidden layer\n","        out  = self.linear_2(out)\n","        ### Non-linearity in 2nd hidden layer\n","        out = self.relu_2(out)\n","        \n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","# INSTANTIATE MODEL CLASS\n","\n","model = DeepNeuralNetworkModel(input_size = input_dim,\n","                               num_classes = output_dim,\n","                               num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","# INSTANTIATE LOSS & OPTIMIZER CLASS\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration: 500. Loss: 0.37975171208381653. Accuracy: 91.49\n","Iteration: 1000. Loss: 0.24391944706439972. Accuracy: 93.71\n","Iteration: 1500. Loss: 0.12966516613960266. Accuracy: 94.85\n","Iteration: 2000. Loss: 0.165731281042099. Accuracy: 95.82\n","Iteration: 2500. Loss: 0.1817249059677124. Accuracy: 96.1\n","Iteration: 3000. Loss: 0.13046735525131226. Accuracy: 96.73\n"]}]},{"cell_type":"markdown","metadata":{"id":"JYdiRLt3FPLy"},"source":["## Three Layer FNN with ReLU Activation"]},{"cell_type":"code","metadata":{"id":"T0jY7KZ0E50C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630851881188,"user_tz":-360,"elapsed":28183,"user":{"displayName":"Saif Chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjI_ChR_dIgUZZL7CmfoRYmN8OuN25b6VPHp7wr=s64","userId":"11355659780488518424"}},"outputId":"00a1e585-724a-4195-bb3d-f0fe08881231"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 #num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class DeepNeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer: 784 --> 100\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","        ### Non-linearity in 1st hidden layer\n","        self.relu_1 = nn.ReLU()\n","\n","        ### 2nd hidden layer: 100 --> 100\n","        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n","        ### Non-linearity in 2nd hidden layer\n","        self.relu_2 = nn.ReLU()\n","\n","        ### 3rd hidden layer: 100 --> 100\n","        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n","        ### Non-linearity in 3rd hidden layer\n","        self.relu_3 = nn.ReLU()\n","\n","        ### Output layer: 100 --> 10\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        ### 1st hidden layer\n","        out  = self.linear_1(x)\n","        ### Non-linearity in 1st hidden layer\n","        out = self.relu_1(out)\n","        \n","        ### 2nd hidden layer\n","        out  = self.linear_2(out)\n","        ### Non-linearity in 2nd hidden layer\n","        out = self.relu_2(out)\n","\n","        ### 3rd hidden layer\n","        out  = self.linear_3(out)\n","        ### Non-linearity in 3rd hidden layer\n","        out = self.relu_3(out)\n","        \n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","# INSTANTIATE MODEL CLASS\n","\n","model = DeepNeuralNetworkModel(input_size = input_dim,\n","                               num_classes = output_dim,\n","                               num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","# INSTANTIATE LOSS & OPTIMIZER CLASS\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration: 500. Loss: 0.5209646821022034. Accuracy: 90.42\n","Iteration: 1000. Loss: 0.17885151505470276. Accuracy: 94.69\n","Iteration: 1500. Loss: 0.22241471707820892. Accuracy: 94.28\n","Iteration: 2000. Loss: 0.10095949470996857. Accuracy: 95.98\n","Iteration: 2500. Loss: 0.14839619398117065. Accuracy: 96.57\n","Iteration: 3000. Loss: 0.05150819197297096. Accuracy: 96.75\n"]}]},{"cell_type":"markdown","metadata":{"id":"-1vTvfpkNjHL"},"source":["## What's Next?\n","\n","- Try with other activations from Pytorch. \n","- Try different activations for different layers (We used ReLU Only)\n","- Try adding more hidden layers \n","- Try increasing the hidden layer neurons (We used 100 here in this example)\n","- Try experimenting with different neurons for different hidden layers (We here in this examples used a fixed sixe: 100)\n","\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1VYlYjGEYo6JKsiADnzOCNM2TPkhNI-Yq\" width=\"230\" height=\"580\">\n","</div>\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1hMrKBdhQ8cmhxGgCzFczQi4xpHMsHufD\" width=\"680\" height=\"280\">\n","</div>\n","\n"]}]}